{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I normalized images between [0, 1] since the CNN converges faster in this range than it does in [0,255]. I also reshaped the images to (60000,28,28,1) and (10000,28,28,1). 1 represents the canal for gray scale images. (e.g canal is 3 for RGB). I also tried mean subtraction and variance normalization but it didn't work out so I gave up on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "#mean=(x_train.mean()+x_test.mean())/2\n",
    "#std=(x_train.std()+x_test.std())/2\n",
    "#x_train=(x_train-mean)/std\n",
    "#x_test=(x_test-mean)/std\n",
    "x_train = x_train.reshape(x_train.shape[0], *(28,28,1))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(28,28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made sure that x is image data and y is label. I shuffled and split the training data to create a separate validation set. train_test_split both shuffles and splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (54000, 28, 28, 1)\n",
      "y_train shape:  (54000,)\n",
      "x_validation shape:  (6000, 28, 28, 1)\n",
      "y_validation shape:  (6000,)\n",
      "x_test shape:  (10000, 28, 28, 1)\n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.1, random_state = 19052005)\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('x_validation shape: ', x_validation.shape)\n",
    "print('y_validation shape: ', y_validation.shape)\n",
    "print('x_test shape: ', x_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I realized that this dataset is prone to overfitting. I used multiple Dropout layers to avoid that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 357,642\n",
      "Trainable params: 357,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "cnn_model.add(Dropout(0.35))\n",
    "cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(Dropout(0.35))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(units = 256, activation = 'relu'))\n",
    "cnn_model.add(Dropout(0.4))\n",
    "cnn_model.add(Dense(units = 10, activation = 'softmax'))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose Adam Optimizer. For the learning rate I use a trick called annealing. With high learning rates the model converges faster. However, low learning rates are better at finding the global minima. Hence, I make my learning rate start high first and get lower when necessary. <em>This is the specifically tricky part of my model.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001),metrics =['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied data augmentation on training data right before the training. Out of Feature Standardization, ZCA Whitening, Random Zoom; I only used Feature Standardization since only that boosted the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      " - 252s - loss: 0.5729 - acc: 0.7863 - val_loss: 0.3088 - val_acc: 0.8838\n",
      "Epoch 2/50\n",
      " - 241s - loss: 0.3466 - acc: 0.8731 - val_loss: 0.2925 - val_acc: 0.8880\n",
      "Epoch 3/50\n",
      " - 243s - loss: 0.2981 - acc: 0.8914 - val_loss: 0.2338 - val_acc: 0.9118\n",
      "Epoch 4/50\n",
      " - 245s - loss: 0.2717 - acc: 0.9006 - val_loss: 0.2254 - val_acc: 0.9153\n",
      "Epoch 5/50\n",
      " - 238s - loss: 0.2549 - acc: 0.9060 - val_loss: 0.2135 - val_acc: 0.9202\n",
      "Epoch 6/50\n",
      " - 240s - loss: 0.2408 - acc: 0.9114 - val_loss: 0.2116 - val_acc: 0.9197\n",
      "Epoch 7/50\n",
      " - 237s - loss: 0.2305 - acc: 0.9156 - val_loss: 0.2072 - val_acc: 0.9245\n",
      "Epoch 8/50\n",
      " - 246s - loss: 0.2199 - acc: 0.9191 - val_loss: 0.2023 - val_acc: 0.9248\n",
      "Epoch 9/50\n",
      " - 227s - loss: 0.2122 - acc: 0.9211 - val_loss: 0.1931 - val_acc: 0.9238\n",
      "Epoch 10/50\n",
      " - 856s - loss: 0.2034 - acc: 0.9252 - val_loss: 0.1856 - val_acc: 0.9308\n",
      "Epoch 11/50\n",
      " - 264s - loss: 0.1968 - acc: 0.9277 - val_loss: 0.1854 - val_acc: 0.9288\n",
      "Epoch 12/50\n",
      " - 256s - loss: 0.1935 - acc: 0.9270 - val_loss: 0.1912 - val_acc: 0.9283\n",
      "Epoch 13/50\n",
      " - 247s - loss: 0.1900 - acc: 0.9294 - val_loss: 0.1879 - val_acc: 0.9333\n",
      "Epoch 14/50\n",
      " - 226s - loss: 0.1846 - acc: 0.9319 - val_loss: 0.1841 - val_acc: 0.9328\n",
      "Epoch 15/50\n",
      " - 319s - loss: 0.1819 - acc: 0.9326 - val_loss: 0.1849 - val_acc: 0.9317\n",
      "Epoch 16/50\n",
      " - 225s - loss: 0.1783 - acc: 0.9325 - val_loss: 0.1762 - val_acc: 0.9342\n",
      "Epoch 17/50\n",
      " - 235s - loss: 0.1712 - acc: 0.9364 - val_loss: 0.1775 - val_acc: 0.9332\n",
      "Epoch 18/50\n",
      " - 246s - loss: 0.1690 - acc: 0.9359 - val_loss: 0.1768 - val_acc: 0.9385\n",
      "Epoch 19/50\n",
      " - 232s - loss: 0.1674 - acc: 0.9376 - val_loss: 0.1878 - val_acc: 0.9337\n",
      "Epoch 20/50\n",
      " - 230s - loss: 0.1636 - acc: 0.9384 - val_loss: 0.1872 - val_acc: 0.9333\n",
      "Epoch 21/50\n",
      " - 239s - loss: 0.1640 - acc: 0.9387 - val_loss: 0.1803 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 22/50\n",
      " - 250s - loss: 0.1414 - acc: 0.9469 - val_loss: 0.1745 - val_acc: 0.9380\n",
      "Epoch 23/50\n",
      " - 242s - loss: 0.1348 - acc: 0.9483 - val_loss: 0.1736 - val_acc: 0.9387\n",
      "Epoch 24/50\n",
      " - 234s - loss: 0.1308 - acc: 0.9500 - val_loss: 0.1757 - val_acc: 0.9435\n",
      "Epoch 25/50\n",
      " - 224s - loss: 0.1263 - acc: 0.9516 - val_loss: 0.1751 - val_acc: 0.9422\n",
      "Epoch 26/50\n",
      " - 222s - loss: 0.1267 - acc: 0.9521 - val_loss: 0.1794 - val_acc: 0.9400\n",
      "Epoch 27/50\n",
      " - 208s - loss: 0.1227 - acc: 0.9537 - val_loss: 0.1775 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/50\n",
      " - 208s - loss: 0.1149 - acc: 0.9565 - val_loss: 0.1722 - val_acc: 0.9432\n",
      "Epoch 29/50\n",
      " - 260s - loss: 0.1100 - acc: 0.9576 - val_loss: 0.1752 - val_acc: 0.9412\n",
      "Epoch 30/50\n",
      " - 256s - loss: 0.1091 - acc: 0.9586 - val_loss: 0.1731 - val_acc: 0.9437\n",
      "Epoch 31/50\n",
      " - 235s - loss: 0.1053 - acc: 0.9607 - val_loss: 0.1761 - val_acc: 0.9423\n",
      "Epoch 32/50\n",
      " - 262s - loss: 0.1040 - acc: 0.9608 - val_loss: 0.1730 - val_acc: 0.9430\n",
      "Epoch 33/50\n",
      " - 265s - loss: 0.1035 - acc: 0.9605 - val_loss: 0.1773 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 34/50\n",
      " - 265s - loss: 0.0994 - acc: 0.9630 - val_loss: 0.1756 - val_acc: 0.9445\n",
      "Epoch 35/50\n",
      " - 210s - loss: 0.0982 - acc: 0.9622 - val_loss: 0.1724 - val_acc: 0.9432\n",
      "Epoch 36/50\n",
      " - 210s - loss: 0.0948 - acc: 0.9644 - val_loss: 0.1745 - val_acc: 0.9427\n",
      "Epoch 37/50\n",
      " - 210s - loss: 0.0942 - acc: 0.9641 - val_loss: 0.1752 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 38/50\n",
      " - 1300s - loss: 0.0931 - acc: 0.9637 - val_loss: 0.1755 - val_acc: 0.9430\n",
      "Epoch 39/50\n",
      " - 226s - loss: 0.0926 - acc: 0.9643 - val_loss: 0.1736 - val_acc: 0.9430\n",
      "Epoch 40/50\n",
      " - 226s - loss: 0.0903 - acc: 0.9653 - val_loss: 0.1759 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 41/50\n",
      " - 247s - loss: 0.0887 - acc: 0.9657 - val_loss: 0.1759 - val_acc: 0.9437\n",
      "Epoch 42/50\n",
      " - 228s - loss: 0.0884 - acc: 0.9660 - val_loss: 0.1764 - val_acc: 0.9435\n",
      "Epoch 43/50\n",
      " - 232s - loss: 0.0875 - acc: 0.9671 - val_loss: 0.1758 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 44/50\n",
      " - 257s - loss: 0.0878 - acc: 0.9668 - val_loss: 0.1759 - val_acc: 0.9428\n",
      "Epoch 45/50\n",
      " - 248s - loss: 0.0896 - acc: 0.9659 - val_loss: 0.1759 - val_acc: 0.9433\n",
      "Epoch 46/50\n",
      " - 252s - loss: 0.0875 - acc: 0.9664 - val_loss: 0.1765 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 47/50\n",
      " - 236s - loss: 0.0874 - acc: 0.9670 - val_loss: 0.1758 - val_acc: 0.9437\n",
      "Epoch 48/50\n",
      " - 212s - loss: 0.0894 - acc: 0.9665 - val_loss: 0.1758 - val_acc: 0.9437\n",
      "Epoch 49/50\n",
      " - 1388s - loss: 0.0856 - acc: 0.9671 - val_loss: 0.1755 - val_acc: 0.9435\n",
      "Epoch 50/50\n",
      " - 268s - loss: 0.0878 - acc: 0.9657 - val_loss: 0.1756 - val_acc: 0.9443\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size=64\n",
    "history = cnn_model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = epochs,\n",
    "                        verbose = 2,\n",
    "                        validation_data = (x_validation, y_validation), callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to find the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Test Accuracy : 0.940\n"
     ]
    }
   ],
   "source": [
    "evaluation = cnn_model.evaluate(x_test, y_test)\n",
    "print('Test Accuracy : {:.3f}'.format(evaluation[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Report:\n",
    "\n",
    "I actually used Google Colab for their GPU while training the model. I modified my method a couple of times. This was possible because of the GPU provided by Google. In the docker image, the program works on a CPU and one epoch takes almost thirty times how much it would take on a GPU. However, my computer got broken and I was able to finish it on my sister's computer without any further installation. This is the good thing about Docker.\n",
    "\n",
    "I found 0.9414 accuracy with the current model. I think I achieved such a result by overfitting avoidance, adaptive learning rate and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
